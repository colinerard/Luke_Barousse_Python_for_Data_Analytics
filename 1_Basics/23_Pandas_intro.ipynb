{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23 Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Industry standard to handle tabular data, like excel, csv, SQL, etc.\n",
    "\n",
    "For any info, go on the [website](https://pandas.pydata.org/)\n",
    "\n",
    "Go to the [API reference page](https://pandas.pydata.org/docs/reference/index.html). We'll be referencing it often in this section and going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package           Version\n",
      "----------------- -----------\n",
      "asttokens         2.4.1\n",
      "colorama          0.4.6\n",
      "comm              0.2.2\n",
      "debugpy           1.8.7\n",
      "decorator         5.1.1\n",
      "executing         2.1.0\n",
      "ipykernel         6.29.5\n",
      "ipython           8.28.0\n",
      "jedi              0.19.1\n",
      "jupyter_client    8.6.3\n",
      "jupyter_core      5.7.2\n",
      "matplotlib-inline 0.1.7\n",
      "nest-asyncio      1.6.0\n",
      "numpy             2.1.2\n",
      "packaging         24.1\n",
      "pandas            2.2.3\n",
      "parso             0.8.4\n",
      "platformdirs      4.3.6\n",
      "prompt_toolkit    3.0.48\n",
      "psutil            6.0.0\n",
      "pure_eval         0.2.3\n",
      "Pygments          2.18.0\n",
      "pyjokes           0.8.3\n",
      "python-dateutil   2.9.0.post0\n",
      "pytz              2024.2\n",
      "pywin32           307\n",
      "pyzmq             26.2.0\n",
      "six               1.16.0\n",
      "stack-data        0.6.3\n",
      "tornado           6.4.1\n",
      "traitlets         5.14.3\n",
      "typing_extensions 4.12.2\n",
      "tzdata            2024.2\n",
      "wcwidth           0.2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\erard\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of functions that will be useful are the:\n",
    "- pandas.read_excel\n",
    "- pandas.read_csv\n",
    "\n",
    "We'll use these functions to access data and access it via a data frame.\n",
    "We'll access some sample data from a Google jupiter notebook that is saved in a specific local folder for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\erard\\OneDrive\\Documents\\Training\\Luke_Barousse_Python_for_Data_Analytics\\1_Basics\\test_csv\\california_housing_test.csv\")\n",
    "\n",
    "# need to wrap the file path in double quotes and add r before to transform the path into a raw path.\n",
    "\n",
    "# df is used as a common name to define a dataframe variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.05</td>\n",
       "      <td>37.37</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3885.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>6.6085</td>\n",
       "      <td>344700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-118.30</td>\n",
       "      <td>34.26</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>809.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>3.5990</td>\n",
       "      <td>176500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-117.81</td>\n",
       "      <td>33.78</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3589.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>5.7934</td>\n",
       "      <td>270500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-118.36</td>\n",
       "      <td>33.82</td>\n",
       "      <td>28.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.1359</td>\n",
       "      <td>330000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-119.67</td>\n",
       "      <td>36.33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2.9375</td>\n",
       "      <td>81700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>-119.86</td>\n",
       "      <td>34.42</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>1.1790</td>\n",
       "      <td>225000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>-118.14</td>\n",
       "      <td>34.06</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5257.0</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>3496.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>3.3906</td>\n",
       "      <td>237200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>-119.70</td>\n",
       "      <td>36.30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2.2895</td>\n",
       "      <td>62000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>-117.12</td>\n",
       "      <td>34.10</td>\n",
       "      <td>40.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.2708</td>\n",
       "      <td>162500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>-119.63</td>\n",
       "      <td>34.42</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1765.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>8.5608</td>\n",
       "      <td>500001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0       -122.05     37.37                27.0       3885.0           661.0   \n",
       "1       -118.30     34.26                43.0       1510.0           310.0   \n",
       "2       -117.81     33.78                27.0       3589.0           507.0   \n",
       "3       -118.36     33.82                28.0         67.0            15.0   \n",
       "4       -119.67     36.33                19.0       1241.0           244.0   \n",
       "...         ...       ...                 ...          ...             ...   \n",
       "2995    -119.86     34.42                23.0       1450.0           642.0   \n",
       "2996    -118.14     34.06                27.0       5257.0          1082.0   \n",
       "2997    -119.70     36.30                10.0        956.0           201.0   \n",
       "2998    -117.12     34.10                40.0         96.0            14.0   \n",
       "2999    -119.63     34.42                42.0       1765.0           263.0   \n",
       "\n",
       "      population  households  median_income  median_house_value  \n",
       "0         1537.0       606.0         6.6085            344700.0  \n",
       "1          809.0       277.0         3.5990            176500.0  \n",
       "2         1484.0       495.0         5.7934            270500.0  \n",
       "3           49.0        11.0         6.1359            330000.0  \n",
       "4          850.0       237.0         2.9375             81700.0  \n",
       "...          ...         ...            ...                 ...  \n",
       "2995      1258.0       607.0         1.1790            225000.0  \n",
       "2996      3496.0      1036.0         3.3906            237200.0  \n",
       "2997       693.0       220.0         2.2895             62000.0  \n",
       "2998        46.0        14.0         3.2708            162500.0  \n",
       "2999       753.0       260.0         8.5608            500001.0  \n",
       "\n",
       "[3000 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "\n",
    "# we have the indexes on the left (starting at 0) and the column names on the top. \n",
    "# the data is layed out in row and columns\n",
    "# a dataframe is a dict like data type. We can use a similar notation to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        661.0\n",
       "1        310.0\n",
       "2        507.0\n",
       "3         15.0\n",
       "4        244.0\n",
       "         ...  \n",
       "2995     642.0\n",
       "2996    1082.0\n",
       "2997     201.0\n",
       "2998      14.0\n",
       "2999     263.0\n",
       "Name: total_bedrooms, Length: 3000, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only a column\n",
    "df[\"total_bedrooms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        661.0\n",
       "1        310.0\n",
       "2        507.0\n",
       "3         15.0\n",
       "4        244.0\n",
       "         ...  \n",
       "2995     642.0\n",
       "2996    1082.0\n",
       "2997     201.0\n",
       "2998      14.0\n",
       "2999     263.0\n",
       "Name: total_bedrooms, Length: 3000, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use another notation to access the column data\n",
    "\n",
    "df.total_bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661.0\n",
      "661.0\n"
     ]
    }
   ],
   "source": [
    "# to access the data for a specific index\n",
    "print(df.total_bedrooms[0])\n",
    "\n",
    "# could also write it like this\n",
    "print(df[\"total_bedrooms\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access course data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data hosted on hugging face, a great platform to host a dataset. \n",
    "\n",
    "Let's find out how to load a dataset from the website directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\erard\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.1.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\erard\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.2.3)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting huggingface-hub>=0.22.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\erard\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (24.1)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl.metadata (65 kB)\n",
      "     ---------------------------------------- 0.0/65.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.8/65.8 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\erard\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\erard\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\erard\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\erard\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\erard\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\erard\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "   ---------------------------------------- 0.0/471.6 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 297.0/471.6 kB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 471.6/471.6 kB 7.4 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 116.3/116.3 kB ? eta 0:00:00\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "   ---------------------------------------- 0.0/177.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 177.6/177.6 kB ? eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "   ---------------------------------------- 0.0/381.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 381.6/381.6 kB 23.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
      "   ---------------------------------------- 0.0/447.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 447.4/447.4 kB 27.3 MB/s eta 0:00:00\n",
      "Downloading pyarrow-17.0.0-cp311-cp311-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.3/25.2 MB 42.6 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 2.6/25.2 MB 33.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 3.9/25.2 MB 31.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 5.1/25.2 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 6.4/25.2 MB 29.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 7.6/25.2 MB 28.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 8.9/25.2 MB 28.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 10.2/25.2 MB 28.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.3/25.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 12.3/25.2 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.4/25.2 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.2/25.2 MB 27.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.5/25.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.7/25.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.0/25.2 MB 28.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.3/25.2 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.2/25.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.7/25.2 MB 31.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.0/25.2 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.1/25.2 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 162.0/162.0 kB 10.1 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB ? eta 0:00:00\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.4/78.4 kB ? eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 143.5/143.5 kB ? eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.0/63.0 kB ? eta 0:00:00\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "   ---------------------------------------- 0.0/167.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 167.3/167.3 kB ? eta 0:00:00\n",
      "Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.8/101.8 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "   ---------------------------------------- 0.0/70.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 70.4/70.4 kB ? eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 126.3/126.3 kB ? eta 0:00:00\n",
      "Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl (89 kB)\n",
      "   ---------------------------------------- 0.0/89.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 89.6/89.6 kB ? eta 0:00:00\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB ? eta 0:00:00\n",
      "Installing collected packages: xxhash, urllib3, tqdm, pyyaml, pyarrow, propcache, multidict, idna, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 datasets-3.0.1 dill-0.3.8 filelock-3.16.1 frozenlist-1.4.1 fsspec-2024.6.1 huggingface-hub-0.26.1 idna-3.10 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.0 pyarrow-17.0.0 pyyaml-6.0.2 requests-2.32.3 tqdm-4.66.5 urllib3-2.2.3 xxhash-3.5.0 yarl-1.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\erard\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# first thing to do is to run pip install datasets\n",
    "\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to import the load_dataset function from the datasets library\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the path string from the database straight from hugging face by clicking the \"copy\" icon right next to the dataset title on the website\n",
    "\n",
    "dataset = load_dataset(\"lukebarousse/data_jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['job_title_short', 'job_title', 'job_location', 'job_via', 'job_schedule_type', 'job_work_from_home', 'search_location', 'job_posted_date', 'job_no_degree_mention', 'job_health_insurance', 'job_country', 'salary_rate', 'salary_year_avg', 'salary_hour_avg', 'company_name', 'job_skills', 'job_type_skills'],\n",
       "    num_rows: 785741\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to call the dataset itself\n",
    "\n",
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then run a method to transform the dataset into a dataframe and be able to access it.\n",
    "\n",
    "df = dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee MÃ©xico</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785736</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Singapura</td>\n",
       "      <td>melalui Trabajo.org</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2023-03-13 06:16:16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAREERSTAR INTERNATIONAL PTE. LTD.</td>\n",
       "      <td>['bash', 'python', 'perl', 'linux', 'unix', 'k...</td>\n",
       "      <td>{'os': ['linux', 'unix'], 'other': ['kubernete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785737</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CRM Data Analyst</td>\n",
       "      <td>Bad Rodach, Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HABA FAMILYGROUP</td>\n",
       "      <td>['sas', 'sas', 'sql', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['sas', 'excel'], 'programmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785738</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Commercial Analyst - Start Now</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>melalui Ricebowl</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2023-03-12 06:32:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lendlease Corporation</td>\n",
       "      <td>['powerpoint', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['powerpoint', 'excel']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785739</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Principal Associate, Data Engineer (Remote-Eli...</td>\n",
       "      <td>Newark, New Jersey, Amerika Serikat</td>\n",
       "      <td>melalui Recruit.net</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-03-12 06:32:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>['python', 'go', 'nosql', 'sql', 'mongo', 'she...</td>\n",
       "      <td>{'cloud': ['aws', 'snowflake', 'azure', 'redsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785740</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>AWS System Analyst</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui Trigyn</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trigyn</td>\n",
       "      <td>['aws', 'flow']</td>\n",
       "      <td>{'cloud': ['aws'], 'other': ['flow']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785741 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_title_short  \\\n",
       "0       Senior Data Engineer   \n",
       "1               Data Analyst   \n",
       "2              Data Engineer   \n",
       "3              Data Engineer   \n",
       "4              Data Engineer   \n",
       "...                      ...   \n",
       "785736     Software Engineer   \n",
       "785737          Data Analyst   \n",
       "785738      Business Analyst   \n",
       "785739         Data Engineer   \n",
       "785740     Software Engineer   \n",
       "\n",
       "                                                job_title  \\\n",
       "0       Senior Clinical Data Engineer / Principal Clin...   \n",
       "1                                            Data Analyst   \n",
       "2       Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "3       LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
       "4                                  Data Engineer- Sr Jobs   \n",
       "...                                                   ...   \n",
       "785736                                    DevOps Engineer   \n",
       "785737                                   CRM Data Analyst   \n",
       "785738                     Commercial Analyst - Start Now   \n",
       "785739  Principal Associate, Data Engineer (Remote-Eli...   \n",
       "785740                                 AWS System Analyst   \n",
       "\n",
       "                               job_location                    job_via  \\\n",
       "0                             Watertown, CT            via Work Nearby   \n",
       "1              Guadalajara, Jalisco, Mexico           via BeBee MÃ©xico   \n",
       "2                           Berlin, Germany               via LinkedIn   \n",
       "3                           San Antonio, TX          via Diversity.com   \n",
       "4                            Washington, DC         via Clearance Jobs   \n",
       "...                                     ...                        ...   \n",
       "785736                            Singapura        melalui Trabajo.org   \n",
       "785737                   Bad Rodach, Jerman  melalui BeBee Deutschland   \n",
       "785738                             Malaysia           melalui Ricebowl   \n",
       "785739  Newark, New Jersey, Amerika Serikat        melalui Recruit.net   \n",
       "785740                                India             melalui Trigyn   \n",
       "\n",
       "       job_schedule_type  job_work_from_home       search_location  \\\n",
       "0              Full-time               False  Texas, United States   \n",
       "1              Full-time               False                Mexico   \n",
       "2              Full-time               False               Germany   \n",
       "3              Full-time               False  Texas, United States   \n",
       "4              Full-time               False                 Sudan   \n",
       "...                  ...                 ...                   ...   \n",
       "785736   Pekerjaan tetap               False             Singapore   \n",
       "785737   Pekerjaan tetap               False               Germany   \n",
       "785738   Pekerjaan tetap               False              Malaysia   \n",
       "785739   Pekerjaan tetap               False                 Sudan   \n",
       "785740   Pekerjaan tetap               False                 India   \n",
       "\n",
       "            job_posted_date  job_no_degree_mention  job_health_insurance  \\\n",
       "0       2023-06-16 13:44:15                  False                 False   \n",
       "1       2023-01-14 13:18:07                  False                 False   \n",
       "2       2023-10-10 13:14:55                  False                 False   \n",
       "3       2023-07-04 13:01:41                   True                 False   \n",
       "4       2023-08-07 14:29:36                  False                 False   \n",
       "...                     ...                    ...                   ...   \n",
       "785736  2023-03-13 06:16:16                  False                 False   \n",
       "785737  2023-03-12 06:18:18                  False                 False   \n",
       "785738  2023-03-12 06:32:36                  False                 False   \n",
       "785739  2023-03-12 06:32:15                  False                 False   \n",
       "785740  2023-03-13 06:16:31                  False                 False   \n",
       "\n",
       "          job_country salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "0       United States        None              NaN              NaN   \n",
       "1              Mexico        None              NaN              NaN   \n",
       "2             Germany        None              NaN              NaN   \n",
       "3       United States        None              NaN              NaN   \n",
       "4               Sudan        None              NaN              NaN   \n",
       "...               ...         ...              ...              ...   \n",
       "785736      Singapore        None              NaN              NaN   \n",
       "785737        Germany        None              NaN              NaN   \n",
       "785738       Malaysia        None              NaN              NaN   \n",
       "785739          Sudan        None              NaN              NaN   \n",
       "785740          India        None              NaN              NaN   \n",
       "\n",
       "                              company_name  \\\n",
       "0                     Boehringer Ingelheim   \n",
       "1               Hewlett Packard Enterprise   \n",
       "2                 ALPHA Augmented Services   \n",
       "3             Southwest Research Institute   \n",
       "4                          Kristina Daniel   \n",
       "...                                    ...   \n",
       "785736  CAREERSTAR INTERNATIONAL PTE. LTD.   \n",
       "785737                    HABA FAMILYGROUP   \n",
       "785738               Lendlease Corporation   \n",
       "785739                         Capital One   \n",
       "785740                              Trigyn   \n",
       "\n",
       "                                               job_skills  \\\n",
       "0                                                    None   \n",
       "1       ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2       ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "3       ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
       "4       ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
       "...                                                   ...   \n",
       "785736  ['bash', 'python', 'perl', 'linux', 'unix', 'k...   \n",
       "785737                     ['sas', 'sas', 'sql', 'excel']   \n",
       "785738                            ['powerpoint', 'excel']   \n",
       "785739  ['python', 'go', 'nosql', 'sql', 'mongo', 'she...   \n",
       "785740                                    ['aws', 'flow']   \n",
       "\n",
       "                                          job_type_skills  \n",
       "0                                                    None  \n",
       "1       {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2       {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
       "3       {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
       "4       {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n",
       "...                                                   ...  \n",
       "785736  {'os': ['linux', 'unix'], 'other': ['kubernete...  \n",
       "785737  {'analyst_tools': ['sas', 'excel'], 'programmi...  \n",
       "785738         {'analyst_tools': ['powerpoint', 'excel']}  \n",
       "785739  {'cloud': ['aws', 'snowflake', 'azure', 'redsh...  \n",
       "785740              {'cloud': ['aws'], 'other': ['flow']}  \n",
       "\n",
       "[785741 rows x 17 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23 Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.23.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the Pandas library under the alias pd.\n",
    "- Import the load_dataset function from datasets library.\n",
    "- Load the course dataset ('lukebarousse/data_jobs') using the load_dataset function.\n",
    "- Transform it into a DataFrame and display the last 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>785736</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Singapura</td>\n",
       "      <td>melalui Trabajo.org</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2023-03-13 06:16:16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAREERSTAR INTERNATIONAL PTE. LTD.</td>\n",
       "      <td>['bash', 'python', 'perl', 'linux', 'unix', 'k...</td>\n",
       "      <td>{'os': ['linux', 'unix'], 'other': ['kubernete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785737</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CRM Data Analyst</td>\n",
       "      <td>Bad Rodach, Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HABA FAMILYGROUP</td>\n",
       "      <td>['sas', 'sas', 'sql', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['sas', 'excel'], 'programmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785738</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Commercial Analyst - Start Now</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>melalui Ricebowl</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2023-03-12 06:32:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lendlease Corporation</td>\n",
       "      <td>['powerpoint', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['powerpoint', 'excel']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785739</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Principal Associate, Data Engineer (Remote-Eli...</td>\n",
       "      <td>Newark, New Jersey, Amerika Serikat</td>\n",
       "      <td>melalui Recruit.net</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-03-12 06:32:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>['python', 'go', 'nosql', 'sql', 'mongo', 'she...</td>\n",
       "      <td>{'cloud': ['aws', 'snowflake', 'azure', 'redsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785740</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>AWS System Analyst</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui Trigyn</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trigyn</td>\n",
       "      <td>['aws', 'flow']</td>\n",
       "      <td>{'cloud': ['aws'], 'other': ['flow']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          job_title_short                                          job_title  \\\n",
       "785736  Software Engineer                                    DevOps Engineer   \n",
       "785737       Data Analyst                                   CRM Data Analyst   \n",
       "785738   Business Analyst                     Commercial Analyst - Start Now   \n",
       "785739      Data Engineer  Principal Associate, Data Engineer (Remote-Eli...   \n",
       "785740  Software Engineer                                 AWS System Analyst   \n",
       "\n",
       "                               job_location                    job_via  \\\n",
       "785736                            Singapura        melalui Trabajo.org   \n",
       "785737                   Bad Rodach, Jerman  melalui BeBee Deutschland   \n",
       "785738                             Malaysia           melalui Ricebowl   \n",
       "785739  Newark, New Jersey, Amerika Serikat        melalui Recruit.net   \n",
       "785740                                India             melalui Trigyn   \n",
       "\n",
       "       job_schedule_type  job_work_from_home search_location  \\\n",
       "785736   Pekerjaan tetap               False       Singapore   \n",
       "785737   Pekerjaan tetap               False         Germany   \n",
       "785738   Pekerjaan tetap               False        Malaysia   \n",
       "785739   Pekerjaan tetap               False           Sudan   \n",
       "785740   Pekerjaan tetap               False           India   \n",
       "\n",
       "            job_posted_date  job_no_degree_mention  job_health_insurance  \\\n",
       "785736  2023-03-13 06:16:16                  False                 False   \n",
       "785737  2023-03-12 06:18:18                  False                 False   \n",
       "785738  2023-03-12 06:32:36                  False                 False   \n",
       "785739  2023-03-12 06:32:15                  False                 False   \n",
       "785740  2023-03-13 06:16:31                  False                 False   \n",
       "\n",
       "       job_country salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "785736   Singapore        None              NaN              NaN   \n",
       "785737     Germany        None              NaN              NaN   \n",
       "785738    Malaysia        None              NaN              NaN   \n",
       "785739       Sudan        None              NaN              NaN   \n",
       "785740       India        None              NaN              NaN   \n",
       "\n",
       "                              company_name  \\\n",
       "785736  CAREERSTAR INTERNATIONAL PTE. LTD.   \n",
       "785737                    HABA FAMILYGROUP   \n",
       "785738               Lendlease Corporation   \n",
       "785739                         Capital One   \n",
       "785740                              Trigyn   \n",
       "\n",
       "                                               job_skills  \\\n",
       "785736  ['bash', 'python', 'perl', 'linux', 'unix', 'k...   \n",
       "785737                     ['sas', 'sas', 'sql', 'excel']   \n",
       "785738                            ['powerpoint', 'excel']   \n",
       "785739  ['python', 'go', 'nosql', 'sql', 'mongo', 'she...   \n",
       "785740                                    ['aws', 'flow']   \n",
       "\n",
       "                                          job_type_skills  \n",
       "785736  {'os': ['linux', 'unix'], 'other': ['kubernete...  \n",
       "785737  {'analyst_tools': ['sas', 'excel'], 'programmi...  \n",
       "785738         {'analyst_tools': ['powerpoint', 'excel']}  \n",
       "785739  {'cloud': ['aws', 'snowflake', 'azure', 'redsh...  \n",
       "785740              {'cloud': ['aws'], 'other': ['flow']}  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steps 1-2-3 ahve already been done above.\n",
    "\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.23.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select and display the job_location column from the course dataset DataFrame you created in the last exercise using bracket notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               Watertown, CT\n",
       "1                Guadalajara, Jalisco, Mexico\n",
       "2                             Berlin, Germany\n",
       "3                             San Antonio, TX\n",
       "4                              Washington, DC\n",
       "                         ...                 \n",
       "785736                              Singapura\n",
       "785737                     Bad Rodach, Jerman\n",
       "785738                               Malaysia\n",
       "785739    Newark, New Jersey, Amerika Serikat\n",
       "785740                                  India\n",
       "Name: job_location, Length: 785741, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"job_location\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.23.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select and display the search_location column from the DataFrame using dot notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Texas, United States\n",
       "1                       Mexico\n",
       "2                      Germany\n",
       "3         Texas, United States\n",
       "4                        Sudan\n",
       "                  ...         \n",
       "785736               Singapore\n",
       "785737                 Germany\n",
       "785738                Malaysia\n",
       "785739                   Sudan\n",
       "785740                   India\n",
       "Name: search_location, Length: 785741, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.search_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.23.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the job_title from the 57th row from the DataFrame using its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Principal Statistical Scientist'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.job_title[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fyi - for any upcoming problem, use the following code to import the dataframe\n",
    "# \n",
    "# import pandas as pd\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset('lukebarousse/data_jobs')\n",
    "# df = dataset['train'].to_pandas() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
