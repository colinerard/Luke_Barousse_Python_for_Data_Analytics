{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Pandas - Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframe is made out of 700k+ rows, however we only have salary information for approx. 33k rows (the remainder of rows are NaN).\n",
    "\n",
    "We have a coworker that wants to have access to a dataset where all the NaN salary values are replaced by the median values for a similar role. They also want any duplicate kob postings to be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading data\n",
    "dataset = load_dataset(\"lukebarousse/data_jobs\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Data cleanup - update date column\n",
    "df[\"job_posted_date\"] = pd.to_datetime(df[\"job_posted_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785736</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Singapura</td>\n",
       "      <td>melalui Trabajo.org</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2023-03-13 06:16:16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAREERSTAR INTERNATIONAL PTE. LTD.</td>\n",
       "      <td>['bash', 'python', 'perl', 'linux', 'unix', 'k...</td>\n",
       "      <td>{'os': ['linux', 'unix'], 'other': ['kubernete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785737</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CRM Data Analyst</td>\n",
       "      <td>Bad Rodach, Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HABA FAMILYGROUP</td>\n",
       "      <td>['sas', 'sas', 'sql', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['sas', 'excel'], 'programmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785738</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Commercial Analyst - Start Now</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>melalui Ricebowl</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2023-03-12 06:32:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lendlease Corporation</td>\n",
       "      <td>['powerpoint', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['powerpoint', 'excel']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785739</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Principal Associate, Data Engineer (Remote-Eli...</td>\n",
       "      <td>Newark, New Jersey, Amerika Serikat</td>\n",
       "      <td>melalui Recruit.net</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-03-12 06:32:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>['python', 'go', 'nosql', 'sql', 'mongo', 'she...</td>\n",
       "      <td>{'cloud': ['aws', 'snowflake', 'azure', 'redsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785740</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>AWS System Analyst</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui Trigyn</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trigyn</td>\n",
       "      <td>['aws', 'flow']</td>\n",
       "      <td>{'cloud': ['aws'], 'other': ['flow']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785741 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_title_short  \\\n",
       "0       Senior Data Engineer   \n",
       "1               Data Analyst   \n",
       "2              Data Engineer   \n",
       "3              Data Engineer   \n",
       "4              Data Engineer   \n",
       "...                      ...   \n",
       "785736     Software Engineer   \n",
       "785737          Data Analyst   \n",
       "785738      Business Analyst   \n",
       "785739         Data Engineer   \n",
       "785740     Software Engineer   \n",
       "\n",
       "                                                job_title  \\\n",
       "0       Senior Clinical Data Engineer / Principal Clin...   \n",
       "1                                            Data Analyst   \n",
       "2       Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "3       LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
       "4                                  Data Engineer- Sr Jobs   \n",
       "...                                                   ...   \n",
       "785736                                    DevOps Engineer   \n",
       "785737                                   CRM Data Analyst   \n",
       "785738                     Commercial Analyst - Start Now   \n",
       "785739  Principal Associate, Data Engineer (Remote-Eli...   \n",
       "785740                                 AWS System Analyst   \n",
       "\n",
       "                               job_location                    job_via  \\\n",
       "0                             Watertown, CT            via Work Nearby   \n",
       "1              Guadalajara, Jalisco, Mexico           via BeBee México   \n",
       "2                           Berlin, Germany               via LinkedIn   \n",
       "3                           San Antonio, TX          via Diversity.com   \n",
       "4                            Washington, DC         via Clearance Jobs   \n",
       "...                                     ...                        ...   \n",
       "785736                            Singapura        melalui Trabajo.org   \n",
       "785737                   Bad Rodach, Jerman  melalui BeBee Deutschland   \n",
       "785738                             Malaysia           melalui Ricebowl   \n",
       "785739  Newark, New Jersey, Amerika Serikat        melalui Recruit.net   \n",
       "785740                                India             melalui Trigyn   \n",
       "\n",
       "       job_schedule_type  job_work_from_home       search_location  \\\n",
       "0              Full-time               False  Texas, United States   \n",
       "1              Full-time               False                Mexico   \n",
       "2              Full-time               False               Germany   \n",
       "3              Full-time               False  Texas, United States   \n",
       "4              Full-time               False                 Sudan   \n",
       "...                  ...                 ...                   ...   \n",
       "785736   Pekerjaan tetap               False             Singapore   \n",
       "785737   Pekerjaan tetap               False               Germany   \n",
       "785738   Pekerjaan tetap               False              Malaysia   \n",
       "785739   Pekerjaan tetap               False                 Sudan   \n",
       "785740   Pekerjaan tetap               False                 India   \n",
       "\n",
       "           job_posted_date  job_no_degree_mention  job_health_insurance  \\\n",
       "0      2023-06-16 13:44:15                  False                 False   \n",
       "1      2023-01-14 13:18:07                  False                 False   \n",
       "2      2023-10-10 13:14:55                  False                 False   \n",
       "3      2023-07-04 13:01:41                   True                 False   \n",
       "4      2023-08-07 14:29:36                  False                 False   \n",
       "...                    ...                    ...                   ...   \n",
       "785736 2023-03-13 06:16:16                  False                 False   \n",
       "785737 2023-03-12 06:18:18                  False                 False   \n",
       "785738 2023-03-12 06:32:36                  False                 False   \n",
       "785739 2023-03-12 06:32:15                  False                 False   \n",
       "785740 2023-03-13 06:16:31                  False                 False   \n",
       "\n",
       "          job_country salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "0       United States        None              NaN              NaN   \n",
       "1              Mexico        None              NaN              NaN   \n",
       "2             Germany        None              NaN              NaN   \n",
       "3       United States        None              NaN              NaN   \n",
       "4               Sudan        None              NaN              NaN   \n",
       "...               ...         ...              ...              ...   \n",
       "785736      Singapore        None              NaN              NaN   \n",
       "785737        Germany        None              NaN              NaN   \n",
       "785738       Malaysia        None              NaN              NaN   \n",
       "785739          Sudan        None              NaN              NaN   \n",
       "785740          India        None              NaN              NaN   \n",
       "\n",
       "                              company_name  \\\n",
       "0                     Boehringer Ingelheim   \n",
       "1               Hewlett Packard Enterprise   \n",
       "2                 ALPHA Augmented Services   \n",
       "3             Southwest Research Institute   \n",
       "4                          Kristina Daniel   \n",
       "...                                    ...   \n",
       "785736  CAREERSTAR INTERNATIONAL PTE. LTD.   \n",
       "785737                    HABA FAMILYGROUP   \n",
       "785738               Lendlease Corporation   \n",
       "785739                         Capital One   \n",
       "785740                              Trigyn   \n",
       "\n",
       "                                               job_skills  \\\n",
       "0                                                    None   \n",
       "1       ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2       ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "3       ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
       "4       ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
       "...                                                   ...   \n",
       "785736  ['bash', 'python', 'perl', 'linux', 'unix', 'k...   \n",
       "785737                     ['sas', 'sas', 'sql', 'excel']   \n",
       "785738                            ['powerpoint', 'excel']   \n",
       "785739  ['python', 'go', 'nosql', 'sql', 'mongo', 'she...   \n",
       "785740                                    ['aws', 'flow']   \n",
       "\n",
       "                                          job_type_skills  \n",
       "0                                                    None  \n",
       "1       {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2       {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
       "3       {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
       "4       {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n",
       "...                                                   ...  \n",
       "785736  {'os': ['linux', 'unix'], 'other': ['kubernete...  \n",
       "785737  {'analyst_tools': ['sas', 'excel'], 'programmi...  \n",
       "785738         {'analyst_tools': ['powerpoint', 'excel']}  \n",
       "785739  {'cloud': ['aws', 'snowflake', 'azure', 'redsh...  \n",
       "785740              {'cloud': ['aws'], 'other': ['flow']}  \n",
       "\n",
       "[785741 rows x 17 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115000.0\n",
      "45.97999954223633\n"
     ]
    }
   ],
   "source": [
    "# let's calculate the median values in order to fill in for the missing values\n",
    "\n",
    "median_salary_year = df[\"salary_year_avg\"].median()\n",
    "\n",
    "print(median_salary_year)\n",
    "\n",
    "median_salary_hour = df[\"salary_hour_avg\"].median()\n",
    "\n",
    "print(median_salary_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785736</th>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785737</th>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785738</th>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785739</th>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785740</th>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785741 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary_rate  salary_year_avg  salary_hour_avg\n",
       "0             None         115000.0            45.98\n",
       "1             None         115000.0            45.98\n",
       "2             None         115000.0            45.98\n",
       "3             None         115000.0            45.98\n",
       "4             None         115000.0            45.98\n",
       "...            ...              ...              ...\n",
       "785736        None         115000.0            45.98\n",
       "785737        None         115000.0            45.98\n",
       "785738        None         115000.0            45.98\n",
       "785739        None         115000.0            45.98\n",
       "785740        None         115000.0            45.98\n",
       "\n",
       "[785741 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do we fill in the empty values without replacing the ones with info?\n",
    "# pandas has the pandas.DataFrame.fillna() method :)\n",
    "\n",
    "# always create another df to keep the original one intact\n",
    "df_filled = df\n",
    "\n",
    "# we then update the info for each column\n",
    "# we have to put it equal to itself to actually replace the NaN values\n",
    "df_filled[\"salary_year_avg\"] = df[\"salary_year_avg\"].fillna(median_salary_year)\n",
    "df_filled[\"salary_hour_avg\"] = df[\"salary_hour_avg\"].fillna(median_salary_hour)\n",
    "\n",
    "# checking that it worked\n",
    "df.loc[:, \"salary_rate\":\"salary_hour_avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original df:            785741\n",
      "Length of drop duplicates df:     785640\n",
      "Rows dropped:                     101\n"
     ]
    }
   ],
   "source": [
    "# now let's drop duplicates.\n",
    "# pandas has a method: pandas.DataFrame.drop_duplicates() that returns a df with duplicate rows remove\n",
    "\n",
    "# new df\n",
    "df_unique = df_filled\n",
    "\n",
    "# removing duplicate rows (based on all columns)\n",
    "df_unique = df_unique.drop_duplicates()\n",
    "\n",
    "# checking how many rows have been removed\n",
    "print(\"Length of original df:           \", len(df_filled))\n",
    "print(\"Length of drop duplicates df:    \", len(df_unique))\n",
    "print(\"Rows dropped:                    \", len(df_filled)-len(df_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original df:            785741\n",
      "Length of drop duplicates df:     508042\n",
      "Rows dropped:                     277699\n"
     ]
    }
   ],
   "source": [
    "# the above doesn't find many exact duplicates across all columns. \n",
    "# let's precise the columns we want to use to search for duplicates: job_title and company_name\n",
    "\n",
    "# removing duplicate rows\n",
    "df_unique = df_unique.drop_duplicates(subset=[\"job_title\", \"company_name\"])\n",
    "\n",
    "# checking how many rows have been removed\n",
    "print(\"Length of original df:           \", len(df_filled))\n",
    "print(\"Length of drop duplicates df:    \", len(df_unique))\n",
    "print(\"Rows dropped:                    \", len(df_filled)-len(df_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows where the salary_year_avg column has missing values. Display the number of rows before and after removing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original dataframe:     785741\n",
      "Length of update dataframe:       785741\n",
      "Rows with missing salary info:    0\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df\n",
    "\n",
    "df_cleaned = df_cleaned.dropna(subset=[\"salary_year_avg\"])\n",
    "\n",
    "print(\"Length of original dataframe:    \", len(df))\n",
    "print(\"Length of update dataframe:      \", len(df_cleaned))\n",
    "print(\"Rows with missing salary info:   \", len(df)-len(df_cleaned))\n",
    "\n",
    "# this is giving us the same number of rows because we have filled the NaN values above :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate rows from the DataFrame based on the job_location column. Display the number of rows before and after removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original dataframe:     785741\n",
      "Length of update dataframe:       17218\n",
      "Rows with missing salary info:    768523\n"
     ]
    }
   ],
   "source": [
    "df_location_clean = df\n",
    "\n",
    "df_location_clean = df_location_clean.drop_duplicates(subset=[\"job_location\"])\n",
    "\n",
    "print(\"Length of original dataframe:    \", len(df))\n",
    "print(\"Length of update dataframe:      \", len(df_location_clean))\n",
    "print(\"Rows with duplicate info:   \", len(df)-len(df_location_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values in the salary_rate column with the string 'Unknown'. Display the first 10 rows of the salary_rate column before and after filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     None\n",
      "1     None\n",
      "2     None\n",
      "3     None\n",
      "4     None\n",
      "5     None\n",
      "6     None\n",
      "7     None\n",
      "8     None\n",
      "9     None\n",
      "10    None\n",
      "Name: salary_rate, dtype: object\n",
      "0     Unknown\n",
      "1     Unknown\n",
      "2     Unknown\n",
      "3     Unknown\n",
      "4     Unknown\n",
      "5     Unknown\n",
      "6     Unknown\n",
      "7     Unknown\n",
      "8     Unknown\n",
      "9     Unknown\n",
      "10    Unknown\n",
      "Name: salary_rate, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_salary_rate_filled = df\n",
    "\n",
    "df_salary_rate_filled = df_salary_rate_filled.fillna({\"salary_rate\": \"Unknown\"})\n",
    "\n",
    "print(df.loc[:10, \"salary_rate\"])\n",
    "print(df_salary_rate_filled.loc[:10, \"salary_rate\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Luke_Barousse_Python_Course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
